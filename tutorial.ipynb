{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Running Yolo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "## 1. Detect\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
        "\n",
        "```shell\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image\n",
        "                          vid.mp4  # video\n",
        "                          screen  # screenshot\n",
        "                          path/  # directory\n",
        "                         'path/*.jpg'  # glob\n",
        "                         'https://youtu.be/LNwODJXcvt4'  # YouTube\n",
        "                         'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR9ZbuQCH7FX",
        "outputId": "284ef04b-1596-412f-88f6-948828dd2b49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at 'C:\\Users\\djonq\\AppData\\Roaming\\Ultralytics\\settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113', 'torchvision==0.13.1+cu113 --index-url https://download.pytorch.org/whl/cu113', 'torchaudio==0.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113'] not found, attempting AutoUpdate...\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ AutoUpdate skipped (offline)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5/yolov5s.pt'], source=yolov5/data/images, data=yolov5\\data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5  2024-10-11 Python-3.9.13 torch-2.4.1+cpu CPU\n",
            "\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5\\yolov5s.pt...\n",
            "\n",
            "  0%|          | 0.00/14.1M [00:00<?, ?B/s]\n",
            "  6%|▌         | 896k/14.1M [00:00<00:01, 7.95MB/s]\n",
            " 14%|█▍        | 2.00M/14.1M [00:00<00:01, 10.0MB/s]\n",
            " 22%|██▏       | 3.12M/14.1M [00:00<00:01, 10.8MB/s]\n",
            " 31%|███       | 4.38M/14.1M [00:00<00:00, 11.2MB/s]\n",
            " 39%|███▉      | 5.50M/14.1M [00:00<00:00, 11.4MB/s]\n",
            " 47%|████▋     | 6.62M/14.1M [00:00<00:00, 11.5MB/s]\n",
            " 55%|█████▍    | 7.75M/14.1M [00:00<00:00, 11.6MB/s]\n",
            " 63%|██████▎   | 8.88M/14.1M [00:00<00:00, 11.6MB/s]\n",
            " 72%|███████▏  | 10.1M/14.1M [00:00<00:00, 11.7MB/s]\n",
            " 81%|████████  | 11.4M/14.1M [00:01<00:00, 11.7MB/s]\n",
            " 89%|████████▊ | 12.5M/14.1M [00:01<00:00, 11.7MB/s]\n",
            " 97%|█████████▋| 13.8M/14.1M [00:01<00:00, 11.7MB/s]\n",
            "100%|██████████| 14.1M/14.1M [00:01<00:00, 11.4MB/s]\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\detect.py\", line 437, in <module>\n",
            "    main(opt)\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\detect.py\", line 432, in main\n",
            "    run(**vars(opt))\n",
            "  File \"c:\\Github\\GrapeDetection\\.env\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\detect.py\", line 179, in run\n",
            "    dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\utils\\dataloaders.py\", line 338, in __init__\n",
            "    raise FileNotFoundError(f\"{p} does not exist\")\n",
            "FileNotFoundError: C:\\Github\\GrapeDetection\\yolov5\\data\\images does not exist\n"
          ]
        }
      ],
      "source": [
        "!python yolov5/detect.py --weights yolov5/yolov5s.pt --img 640 --conf 0.25 --source yolov5/data/images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/127574988-6a558aa1-d268-44b9-bf6b-62d4c605cc72.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "## 2. Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NcFxRcFdJ_O",
        "outputId": "bbeeea2b-04fc-4185-aa64-258690495b5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mgithub: \u001b[0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113', 'torchvision==0.13.1+cu113 --index-url https://download.pytorch.org/whl/cu113', 'torchaudio==0.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113'] not found, attempting AutoUpdate...\n",
            "Retry 1/2 failed: Command 'pip install --no-cache-dir \"torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchvision==0.13.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchaudio==0.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" ' returned non-zero exit status 1.\n",
            "Retry 2/2 failed: Command 'pip install --no-cache-dir \"torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchvision==0.13.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchaudio==0.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" ' returned non-zero exit status 1.\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ Command 'pip install --no-cache-dir \"torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchvision==0.13.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchaudio==0.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" ' returned non-zero exit status 1.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=, data=grapes-detection-3/data.yaml, hyp=yolov5\\data\\hyps\\hyp.scratch-low.yaml, epochs=3, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, evolve_population=yolov5\\data\\hyps, resume_evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=0, project=yolov5\\runs\\train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest, ndjson_console=False, ndjson_file=False\n",
            "ERROR: Invalid requirement: 'torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113'\n",
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'C:\\Github\\GrapeDetection\\.env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
            "ERROR: Invalid requirement: 'torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113'\n",
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'C:\\Github\\GrapeDetection\\.env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\train.py\", line 986, in <module>\n",
            "    main(opt)\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\train.py\", line 672, in main\n",
            "    device = select_device(opt.device, batch_size=opt.batch_size)\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\utils\\torch_utils.py\", line 124, in select_device\n",
            "    assert torch.cuda.is_available() and torch.cuda.device_count() >= len(\n",
            "AssertionError: Invalid CUDA '--device 0' requested, use '--device cpu' or pass valid CUDA device(s)\n"
          ]
        }
      ],
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python yolov5/train.py --batch-size 2 --workers 0  --epochs 3 --data grapes-detection-3/data.yaml  --weights yolov5/yolov5s.pt --device 0 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Detect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113', 'torchvision==0.13.1+cu113 --index-url https://download.pytorch.org/whl/cu113', 'torchaudio==0.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113'] not found, attempting AutoUpdate...\n",
            "Retry 1/2 failed: Command 'pip install --no-cache-dir \"torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchvision==0.13.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchaudio==0.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" ' returned non-zero exit status 1.\n",
            "Retry 2/2 failed: Command 'pip install --no-cache-dir \"torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchvision==0.13.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchaudio==0.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" ' returned non-zero exit status 1.\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ Command 'pip install --no-cache-dir \"torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchvision==0.13.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" \"torchaudio==0.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113\" ' returned non-zero exit status 1.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['.\\\\yolov5\\\\runs\\\\train\\\\exp3\\\\weights\\\\best.pt'], source=.\\Test\\, data=yolov5\\data\\coco128.yaml, imgsz=[640, 640], conf_thres=0.6, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=True, save_format=0, save_csv=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=yolov5\\runs\\detect, name=exp, exist_ok=False, line_thickness=4, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "ERROR: Invalid requirement: 'torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113'\n",
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'C:\\Github\\GrapeDetection\\.env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
            "ERROR: Invalid requirement: 'torch==1.12.1+cu113 --index-url https://download.pytorch.org/whl/cu113'\n",
            "WARNING: You are using pip version 22.0.4; however, version 24.2 is available.\n",
            "You should consider upgrading via the 'C:\\Github\\GrapeDetection\\.env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n",
            "YOLOv5  2024-10-11 Python-3.9.13 torch-2.4.1+cpu CPU\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\detect.py\", line 437, in <module>\n",
            "    main(opt)\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\detect.py\", line 432, in main\n",
            "    run(**vars(opt))\n",
            "  File \"c:\\Github\\GrapeDetection\\.env\\lib\\site-packages\\torch\\utils\\_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\detect.py\", line 166, in run\n",
            "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\models\\common.py\", line 489, in __init__\n",
            "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
            "  File \"c:\\Github\\GrapeDetection\\yolov5\\models\\experimental.py\", line 98, in attempt_load\n",
            "    ckpt = torch.load(attempt_download(w), map_location=\"cpu\")  # load\n",
            "  File \"c:\\Github\\GrapeDetection\\.env\\lib\\site-packages\\ultralytics\\utils\\patches.py\", line 86, in torch_load\n",
            "    return _torch_load(*args, **kwargs)\n",
            "  File \"c:\\Github\\GrapeDetection\\.env\\lib\\site-packages\\torch\\serialization.py\", line 1065, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"c:\\Github\\GrapeDetection\\.env\\lib\\site-packages\\torch\\serialization.py\", line 468, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"c:\\Github\\GrapeDetection\\.env\\lib\\site-packages\\torch\\serialization.py\", line 449, in __init__\n",
            "    super().__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: 'yolov5\\\\runs\\\\train\\\\exp3\\\\weights\\\\best.pt'\n"
          ]
        }
      ],
      "source": [
        "!python .\\yolov5\\detect.py --source .\\Test\\ --weights .\\yolov5\\runs\\train\\exp3\\weights\\best.pt --conf-thres 0.6 --save-txt --line-thickness 4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "YOLOv5 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
